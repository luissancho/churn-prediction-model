{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from lib.WTTE import WTTE\n",
    "from lib.ChurnEnsemble import ChurnEnsemble\n",
    "from lib.utils import format_number, show_summary\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict(\n",
    "    features=[\n",
    "        'plan', 'interval', 'country_es', 'country_mx', 'country_latam', 'gateway_auto',\n",
    "        'failed', 'usage', 'usage_groups', 'usage_payments', 'momentum'\n",
    "    ],\n",
    "    params=dict(\n",
    "        epochs=10,  # Number of epochs\n",
    "        lr=1e-4,  # Learning rate\n",
    "        batch=256,  # Batch size\n",
    "        stop=0,  # Early stopping patience\n",
    "        hl=2,\n",
    "        max_beta=2.\n",
    "    )\n",
    ")\n",
    "\n",
    "max_sl = 24  # Maximum sequence length (0 = max length from data)\n",
    "min_tte = 1  # Minimum time to event for binary classification (positive if `tte` <= `min_tte`)\n",
    "test_size = 0.25  # Percentage of the data to use for test/validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../files/churn-data-fit.csv')\n",
    "\n",
    "for col in ['tp', 'ts', 'te']:\n",
    "    data[col] = pd.to_datetime(data[col])\n",
    "\n",
    "cs = (data.sort_values(['id', 'tfs']).groupby('id')['tte'].last() < 0).value_counts().sort_index().astype(float)\n",
    "print('Total Customers: {} | Censored: {} | Non-censored: {} | Censored Rate {}%'.format(\n",
    "    format_number(cs.sum()),\n",
    "    format_number(cs[1]),\n",
    "    format_number(cs[0]),\n",
    "    format_number(100 * cs[1] / cs.sum(), 2)\n",
    "))\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_split = data.sort_values(['id', 'tp']).groupby('id')['tte'].last().reset_index()\n",
    "d_split['censored'] = d_split['tte'] < 0\n",
    "\n",
    "d_train, d_test = train_test_split(\n",
    "    d_split,\n",
    "    test_size=test_size,\n",
    "    shuffle=True,\n",
    "    stratify=d_split['censored'].astype(int),\n",
    "    random_state=SEED\n",
    ")\n",
    "\n",
    "cs_train = d_train['censored'].value_counts().sort_index().astype(float)\n",
    "cs_test = d_test['censored'].value_counts().sort_index().astype(float)\n",
    "\n",
    "print('Total Customers: {} ({}% censored) | Train: {} ({}%) | Test: {} ({}%)'.format(\n",
    "    format_number(len(d_split)),\n",
    "    format_number(100 * cs[1] / cs.sum(), 2),\n",
    "    format_number(len(d_train)),\n",
    "    format_number(100 * cs_train[1] / cs_train.sum(), 2),\n",
    "    format_number(len(d_test)),\n",
    "    format_number(100 * cs_test[1] / cs_test.sum(), 2)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the WTTE Time To Event model\n",
    "wtte = WTTE(\n",
    "    features=config['features'],\n",
    "    max_sl=max_sl,\n",
    "    min_tte=min_tte,\n",
    "    seed=SEED,\n",
    "    verbose=1,\n",
    "    path='../files/wtte',\n",
    "    **config['params']\n",
    ")\n",
    "\n",
    "wtte.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select train data\n",
    "d_wtte_train = data[data['id'].isin(d_train['id'])].sort_values(['id', 'tfs'])[\n",
    "    ['id', 'tfs', 'tte'] + wtte.features\n",
    "]\n",
    "\n",
    "# Scale/Normalize features\n",
    "wtte.scaler = StandardScaler().fit(d_wtte_train[wtte.features])\n",
    "d_wtte_train[wtte.features] = wtte.scaler.transform(d_wtte_train[wtte.features])\n",
    "\n",
    "# Build train tensor\n",
    "x_wtte_train, y_wtte_train = wtte.build_seq(d_wtte_train, deep=False)\n",
    "df_wtte_train = wtte.seq_to_df(x_wtte_train, y_wtte_train)\n",
    "\n",
    "print(x_wtte_train.shape, y_wtte_train.shape)\n",
    "df_wtte_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select test data\n",
    "d_wtte_test = data[data['id'].isin(d_test['id'])].sort_values(['id', 'tfs'])[\n",
    "    ['id', 'tfs', 'tte'] + wtte.features\n",
    "]\n",
    "\n",
    "# Scale/Normalize features (using the scaler from the training data)\n",
    "d_wtte_test[wtte.features] = wtte.scaler.transform(d_wtte_test[wtte.features])\n",
    "\n",
    "# Build test tensor\n",
    "x_wtte_test, y_wtte_test = wtte.build_seq(d_wtte_test, deep=False)\n",
    "df_wtte_test = wtte.seq_to_df(x_wtte_test, y_wtte_test)\n",
    "\n",
    "print(x_wtte_test.shape, y_wtte_test.shape)\n",
    "df_wtte_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit WTTE model\n",
    "wtte.fit(x_wtte_train, y_wtte_train, x_wtte_test, y_wtte_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "wtte.save()\n",
    "\n",
    "# Plot training history\n",
    "wtte.plot_history_eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wtte.weightwatcher.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get sequence lengths\n",
    "wtte.sls = wtte.get_seq_lengths(y_wtte_test)\n",
    "# Predict\n",
    "y_wtte_hat = wtte.predict(x_wtte_test)\n",
    "# Set results\n",
    "wtte.set_results(y_wtte_hat, y_wtte_test)\n",
    "\n",
    "# Plot the distribution of the Weibull alpha and beta parameters for all customers in the given data.\n",
    "wtte.plot_params_dist(wtte.results, loc=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction results\n",
    "wtte.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select random customers from the results\n",
    "n_samples = 6  # Number of customers\n",
    "min_periods = 6  # Minimum number of periods recorded\n",
    "\n",
    "ids = shuffle(\n",
    "    wtte.sls[wtte.sls['length'] > 6]['id'].tolist()\n",
    ")[:n_samples]\n",
    "\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plot the distribution of the Weibull alpha and beta parameters\n",
    "for a single customer over time, showing how the parameters change\n",
    "from one period to the next as the customer info and usage change.\n",
    "\n",
    "The alpha parameter represents the scale of the Weibull distribution,\n",
    "which denotes the time it takes for the customer to churn,\n",
    "while the beta parameter represents the shape of the Weibull distribution,\n",
    "which is a measure of dispersion, meaning how sure we are about the result.\n",
    "\"\"\"\n",
    "\n",
    "fig, axs = plt.subplots(nrows=2, ncols=3, figsize=(16, 8), constrained_layout=True)\n",
    "axs = axs.flatten()\n",
    "\n",
    "for i, uid in enumerate(ids):\n",
    "    wtte.plot_single_params(wtte.results, id=uid, ax=axs[i])\n",
    "\n",
    "plt.suptitle('Single Weibull Alpha and Beta Evolution', y=1.03)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plot both the probability and cumulative functions for a single customer at a specific period,\n",
    "showing how the survival of the customer is modeled by the Weibull distribution.\n",
    "\n",
    "Basically, the probability function shows the probability of the customer\n",
    "to churn at a given time (the peak of the distribution is the most probable churn period),\n",
    "while the cumulative function shows the probability of the customer to churn before any given time.\n",
    "\"\"\"\n",
    "\n",
    "fig, axs = plt.subplots(nrows=2, ncols=3, figsize=(16, 8), constrained_layout=True)\n",
    "axs = axs.flatten()\n",
    "\n",
    "for i, uid in enumerate(ids):\n",
    "    wtte.plot_weibull(wtte.results, id=uid, loc=-1, ax=axs[i])\n",
    "\n",
    "plt.suptitle('Single WTTE Weibull PDF/CDF Distribution', y=1.03)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the last sequence prediction for each customer\n",
    "results = (\n",
    "    wtte.results\n",
    "    .sort_values(['id', 'tfs'])\n",
    "    .groupby('id')\n",
    "    .last()\n",
    "    .drop(columns=['tfs'])\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "show_summary(results, 'true')\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Ensemble model in order to compute and plot the scores\n",
    "model = ChurnEnsemble(\n",
    "    min_tte=min_tte,\n",
    "    seed=SEED,\n",
    "    verbose=1,\n",
    "    path='../files'\n",
    ")\n",
    "# Set the WTTE model\n",
    "model.wtte = wtte\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute and set scores\n",
    "model.set_scores(wtte.results)\n",
    "\n",
    "# Plot scores summary\n",
    "model.plot_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram of predicted probabilities for each customer sequence\n",
    "model.plot_histogram(wtte.results, loc=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
